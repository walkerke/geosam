---
title: "Getting started with geosam"
format: html
editor: visual
eval: false
---

geosam provides an R interface to Meta's Segment Anything Model 3 (SAM3) for detecting objects in satellite imagery and photos. Unlike traditional computer vision approaches, SAM3 lets you describe what you're looking for in plain text—no training data or model fine-tuning required.

The package is inspired by the Python package [segment-geospatial](https://samgeo.gishub.org/) by Qiusheng Wu, and aims to bring similar functionality to R users. geosam offers an R-native API, linking to packages such as terra for spatial workflows and magick for image manipulation. It also includes tools for interactive viewing and extraction with the mapgl R package.

### Installation

Getting set up with geosam takes a few steps. First, install the package from GitHub:

``` r
remotes::install_github("walkerke/geosam")
```

Or:

``` r
pak::pak("walkerke/geosam")
```

Once installed, load the package then set up a SAM3 Python environment with `geosam_install()`. By default, if run with no arguments, `geosam_install()` will use **uv** for the Python environment.

``` r
library(geosam)
geosam_install()
```

This creates a dedicated uv environment with PyTorch and HuggingFace transformers.

If you prefer to use **venv** or **conda** for Python environment management, you can supply the appropriate argument to `geosam_install()`:

``` r
geosam_install(method = "conda") # or method = "virtualenv"
```

This will set up a Python environment named `geosam` unless you supply an alternative name to `envname`.

#### Windows prerequisites

On Windows, you'll need a couple of additional tools:

-   **Git**: Required to install SAM3 from GitHub. Download from [git-scm.com](https://git-scm.com/download/win) and install with default settings.
-   **Rtools**: Required to compile some R package dependencies. Download from [CRAN](https://cran.r-project.org/bin/windows/Rtools/).

After installing these, restart your R session before running `geosam_install()`.

### Authentication

geosam uses Meta's SAM3 model hosted on HuggingFace, which requires authentication. You'll need to complete two steps: request access to the model, and set up your access token.

#### Requesting SAM3 access

First, visit the [SAM3 model page on HuggingFace](https://huggingface.co/facebook/sam3) and click "Request access." You'll need a free HuggingFace account. Access is typically granted quickly, but may take a few hours.

#### Setting up your access token

Once you have access, you'll need a User Access Token. From your HuggingFace account, go to **Settings \> Access Tokens** and create a new token. A "read" token is sufficient for geosam since we're only downloading model weights—and read tokens are safer in case your token is accidentally exposed.

The easiest way to authenticate is to save the token on your machine using the HuggingFace CLI. From your terminal:

``` bash
huggingface-cli login
```

This saves your token to `~/.cache/huggingface/token`, where geosam will find it automatically.

Alternatively, you can set the token as an environment variable in R. For persistent use across sessions, add it to your `.Renviron` file:

``` r
# Open your .Renviron file
usethis::edit_r_environ()

# Add this line:
# HF_TOKEN=hf_xxxxx
```

Or set it for a single session:

``` r
Sys.setenv(HF_TOKEN = "hf_xxxxx")
```

#### Imagery API keys

For satellite imagery, geosam supports three providers. Mapbox offers high-quality imagery but requires an API key:

``` r
Sys.setenv(MAPBOX_PUBLIC_TOKEN = "pk.xxxxx")
```

Esri World Imagery works without any API key, making it a good option for getting started. MapTiler is also supported with the `MAPTILER_API_KEY` environment variable.

### Check your setup

Before running your first detection, verify that everything is configured correctly:

```{r}
#| echo: false
#| eval: true
library(geosam)
```

```{r}
#| eval: true
geosam_status()
```

This will show you the status of your Python environment, whether GPU acceleration is available (MPS on Apple Silicon, CUDA on NVIDIA), and whether your HuggingFace token is configured. If everything shows green checkmarks, you're ready to go.

### Your first detection

Let's detect football fields on the TCU campus in Fort Worth. The `sam_detect()` function is the main workhorse for satellite imagery detection. You provide a bounding box, describe what you're looking for with a text prompt, and geosam handles the rest—downloading imagery, running SAM3 inference, and returning georeferenced results.

```{r}
#| eval: true

field <- sam_detect(
  bbox = c(-97.372, 32.707, -97.366, 32.712),
  text = "football field",
  source = "mapbox",
  zoom = 17
)

plot(field)
```

The `bbox` argument takes coordinates in WGS84 (longitude/latitude) as `c(xmin, ymin, xmax, ymax)`. You can also pass an sf object and geosam will extract its bounding box automatically.

The first time you run a detection, SAM3 will download model weights from HuggingFace (about 2.5 GB). This only happens once as subsequent runs use the cached model.

### Viewing results

Use `sam_view()` to explore your detections interactively:

``` r
sam_view(field)
```

![](images/paste-8.png)

This opens a Shiny application with the satellite imagery as a basemap and your detections overlaid as polygons. You can adjust the confidence threshold with a slider to filter out lower-quality detections, and click on individual polygons to see their confidence scores. Here, we've picked up the field inside the football stadium as well as the nearby practice field.

Zoom out a bit for this view - you'll see a white box representing the extraction area. This is the area that we searched for features matching the text prompt.

### Extracting polygons

When you're ready to work with the results in R, extract them as an sf object:

```{r}
#| eval: true

field_sf <- sam_as_sf(field)

field_sf
```

The resulting sf object includes a `score` column with confidence values (0–1) and an `area_m2` column with the area of each detection in square meters. From here, you can filter, analyze, or export your detections using standard sf workflows.

### Next steps

-   [Satellite Imagery Detection](satellite-detection.html) - Full guide to geospatial workflows
-   [Regular Image Detection](image-detection.html) - Working with photos and screenshots
-   [Interactive Workflows](interactive.html) - Using the explore and view interfaces